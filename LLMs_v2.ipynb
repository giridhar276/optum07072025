{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDs9DRHeU0lA"
   },
   "source": [
    "#Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fo9M10uMU5Ea"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71ErFfpWi9nh"
   },
   "source": [
    "# LLMs Lab-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGc-TSgxXaKJ"
   },
   "source": [
    "# Accessing OpenAI LLM through an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJMbqMOCYkTY"
   },
   "outputs": [],
   "source": [
    "#!pip3 install OpenAI #llm\n",
    "##!pip3 install langchain\n",
    "#!pip3 install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4c9gz6sXiKX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-6YQXIgD11EZLTp3C2OLvZOMxCnCyTyNM6DQUlLskVtT3BlbkFJ-a-CrSMiA-0CS3iCEJKw1b4JC9JezL2iAy1HWFCTUA\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNdgXtrZXu5_"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.llms\n",
    "dir(langchain.llms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= OpenAI()\n",
    "\n",
    "print(llm.invoke(\"How many minimum sleeping hours you should have?give single liner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#my program ----->langchain framework -----> API -----> openai llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Umq0iTHh4zD5"
   },
   "outputs": [],
   "source": [
    "print(llm.invoke(\"What is the sentiment of this review. Give one word answer Pos or Neg - The staff was friendly and helpful. I had a great experience with my loan officer.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYg-LmG7FDg7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of log messages\n",
    "log_messages = [\n",
    "    \"INFO: Server started successfully\",\n",
    "    \"WARNING: Low disk space\",\n",
    "    \"CRITICAL: Database connection failed\",\n",
    "    \"CRITICAL: Security breach detected\",\n",
    "    \"INFO: New feature released\",\n",
    "]\n",
    "\n",
    "# Create a DataFrame with 10 rows and 1 column\n",
    "df = pd.DataFrame(log_messages, columns=[\"Message\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmNRAj2IGDUe"
   },
   "outputs": [],
   "source": [
    "# Classify each log message using llm.invoke\n",
    "df[\"Sentiment\"] = df[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the severity of this log message make give output as CRITICAL if the message is critical. give one word answer: {message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSf-VSlNGUOg"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "newdf = pd.read_csv(\"statements.csv\")\n",
    "# Classify each log message using llm.invoke\n",
    "newdf\n",
    "newdf[\"Sentiment\"] = newdf[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the statement and give output as positive or negative give one word answer: {message}\"))\n",
    "newdf.to_csv(\"sentimentanalysis.csv\")\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install Cohere #llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['COHERE_API_KEY'] = \"QyAigAO2TiRk13Wjrl1TBJED0oUG4iqQ3ioCHt37\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " According to the Centers for Disease Control and Prevention (CDC), it is recommended that adults aged 18-60 years old should have 7 or more hours of sleep per night. It is also important to note that individuals may require differing amounts of sleep to feel rested and alert. The amount of sleep needed can also vary at different stages of life, such as childhood and adolescence, when individuals may require more sleep. \n",
      "\n",
      "It is recommended that you assess your sleep needs and adjust your sleep schedule accordingly. Taking the time to establish a consistent sleep routine can help you determine the number of hours you need to sleep to feel rested. \n",
      "\n",
      "It is also important to prioritize sleep and practice healthy sleep habits, such as limiting screen time before bed, creating a relaxing sleep environment, and avoiding heavy eating or drinking before sleep. \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import  Cohere\n",
    "\n",
    "llm=Cohere()\n",
    "print(llm.invoke(\"How many minimum sleeping hours you should have?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my program -----> API -----> cohere llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm.invoke(\"What is the sentiment of this review. Give one word answer Pos or Neg - The staff was friendly and helpful. I had a great experience with my loan officer.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Server started successfully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low disk space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Database connection failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Security breach detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New feature released</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Message\n",
       "0  Server started successfully\n",
       "1               Low disk space\n",
       "2   Database connection failed\n",
       "3     Security breach detected\n",
       "4         New feature released"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of log messages\n",
    "log_messages = [\n",
    "    \"Server started successfully\",\n",
    "    \"Low disk space\",\n",
    "    \"Database connection failed\",\n",
    "    \"Security breach detected\",\n",
    "    \"New feature released\",\n",
    "]\n",
    "\n",
    "# Create a DataFrame with 10 rows and 1 column\n",
    "df = pd.DataFrame(log_messages, columns=[\"Message\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each log message using llm.invoke\n",
    "df[\"Sentiment\"] = df[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the severity of this log message make give output as CRITICAL if the message is critical: {message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Server started successfully</td>\n",
       "      <td>The severity of this log message is \"INFO\" \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low disk space</td>\n",
       "      <td>The severity of this log message is \"CRITICAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Database connection failed</td>\n",
       "      <td>CRITICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Security breach detected</td>\n",
       "      <td>CRITICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New feature released</td>\n",
       "      <td>The severity of this log message is NOT CRITI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Message  \\\n",
       "0  Server started successfully   \n",
       "1               Low disk space   \n",
       "2   Database connection failed   \n",
       "3     Security breach detected   \n",
       "4         New feature released   \n",
       "\n",
       "                                           Sentiment  \n",
       "0   The severity of this log message is \"INFO\" \\n...  \n",
       "1   The severity of this log message is \"CRITICAL...  \n",
       "2                                           CRITICAL  \n",
       "3                                           CRITICAL  \n",
       "4   The severity of this log message is NOT CRITI...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def display_sentiment(message):\n",
    "    sentiment = llm.invoke(f\"Classify the severity of this log message make give output as CRITICAL if the message is critical: {message}\")\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "\n",
    "# Classify each log message using llm.invoke\n",
    "df[\"Sentiment\"] = df[\"Message\"].apply(display_sentiment)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34tmhRkC3UwI"
   },
   "source": [
    "# Gen AI - Code Generation in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFNYpN7T3dS-"
   },
   "source": [
    "Import dataset from https://raw.githubusercontent.com/giridhar276/Datasets/master/Automobile%20Data%20Set/AutoDataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuKH7m8mtU66"
   },
   "source": [
    "print number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQcH7mf_taKN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FetJeAZ7ta8F"
   },
   "source": [
    "Print the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR0PGk8UtdyT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz3MastkteiW"
   },
   "source": [
    "Create a bar chart for the 'fuel-type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnOE_ce8tk4J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6KInBkHtlvF"
   },
   "source": [
    "Findout outliers in price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg3j4192tro5"
   },
   "outputs": [],
   "source": [
    "import langchain.llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(langchain.llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM////38NF54/QEhNgT4/i8",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
